# 카프카 컨슈머

컨슈머의 고급 활용법과 옵션별 동작 방식을 알아보자.

<br>

## 멀티 스레드 컨슈머

- 파티션을 여러 개로 운영한다면 파티션 개수와 컨슈머 개수를 동일하게 맞추자.
- 파티션 개수가 n개라면 컨슈머 스레드를 최대 n개 운영할 수 있다.
- 한 컨슈머 스레드에서 예외가 발생 시, 프로세스 자체가 종료될 수 있다.
- 각 스레드 간에 영향이 없도록 스레드 세이프 로직, 변수를 적용해야 한다.

<br>

> **컨슈머를 멀티 스레드로 활용하는 방식**
1. 멀티 워커 스레드 전략
2. 컨슈머 멀티 스레드 전략
> 

<br>

### 카프카 컨슈머 멀티 워커 스레드 전략

컨슈머 스레드는 1개만 실행하고 데이터 처리 담당인 워커 스레드를 여러 개 실행한다.

- 데이터를 워커 스레드에서 병렬 처리해 속도가 빨라진다.
- 자바의 ExecutorService 라이브러리를 사용한다.
    - Executors: 스레드 개수를 제어하는 스레드 풀 생성
    - CachedThreadPool: 스레드 실행


<br>

1개의 애플리케이션에 n개의 컨슈머 스레드 띄우기

```java
public class ConsumerWorker implements Runnable { // 스레드로 실행될 클래스
	
	private Properties prop;        // 카프카 컨슈머 옵션
	private String topic;           // 토픽 이름
	private String threadName;      // 스레드 구별용 번호
	private KafkaConsumer<String, String> consumer;

	ConsumerWorker(Properties prop, String topic, int number) {
		this.prop = prop;
		this.topic = topic;
		this.threadName = "consumer-thread-" + number;
	}

	@Override
	public void run() {
		consumer = new KafkaConsumer<>(prop);
		consumer.subscribe(Arrays.asList(topic));
		while (true) {
			ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
			for (ConsumerRecord<String, String> record : records) {
				logger.info("{}", record);
			}
		}
	}
}
```

<br>

**멀티 컨슈머 스레드 애플리케이션**

```java
public class MultiConsumerThread {
	
	public static void main(String[] args) {
		Properties configs = new Properties();
		configs.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);
		configs.put(ConsumerConfig.GROUP_ID_CONFIG, GROUP_ID);
		...

		ExecutorService executorService = Executors.newCachedThreadPool();
		for (int i = 0; i < CONSUMER_COUNT; i++) {
			ConsumerWorker worker = new ConsumerWorker(configs, TOPIC_NAME, i);
			executorService.execute(worker);
		}
	}
}
```

<br>

**주의할 점**

- 데이터 처리가 끝나지 않았음에도 커밋 → 리밸런싱, 컨슈머 장애 시 데이터 유실
- 레코드 처리의 역전현상

<br>

## 컨슈머 랙(LAG)

- 토픽의 최신 오프셋과 컨슈머 오프셋 간의 차이
- 컨슈머가 정상 동작하는지 여부를 확인할 수 있는 모니터링 지표
- 컨슈머 그룹과 토픽, 파티션 별로 생성

<br>

> **컨슈머 랙 확인 방법**
1. 카프카 명령어 사용
2. metrics() 메서드 사용
3. 외부 모니터링 툴 사용
> 

<br>

1. **카프카 명령어 사용**

```java
$ bin/kafka-consumer-groups.sh --bootstrap-server my-kafka:9092 --group my-group --describe
```

일회성 확인 방법으로 테스트용 카프카에서 주로 사용한다.

<br>

2. **`metrics()` 메서드 사용**

```java
for (Map.Entry(MetricName, ? extends Metric> entry : kafkaConsumer.metrics().entrySet()) {
	if ("records-lag-max".equals(entry.getKey().name()) |
			"records-lag".equals(entry.getKey().name()) |
			"records-lag-avg".equals(entry.getKey().name())) {
		Metric metric = entry.getValue();
		logger.info("{}:{}", entry.getKey().name(), metric.metricValue());
	}
}
```

<br>

`**metrics()` 의 문제점**

1. 컨슈머 정상 동작 상황에서만 확인 가능
2. 모든 컨슈머 애플리케이션에 컨슈머 랙 모니터링 코드 중복
3. 카프카 서드 파티 애플리케이션은 모니터링 불가능


<br>

3. 외부 모니터링 툴 사용
- 가장 최선의 방법
- 클러스터 모니터링과 컨슈머 랙을 함께 또는 컨슈머만 모니터링
- DataDog, Confluent Control Center, Burrow 등


<br>

<br>

### 카프카 버로우

- 링크드인에서 공개한 오픈소스 컨슈머 랙 체크 툴
- REST API로 컨슈머 그룹별 컨슈머 랙 조회
- 슬라이딩 윈도우 계산으로 파티션의 문제를 인식한다.
- 파티션 상태: OK, STALLED, STOPPED
- 컨슈머 상태: OK, WARNING, ERROR

<br>

**컨슈머 랙 모니터링 아키텍처**

- 버로우
- 텔레그래프: 데이터 수집 및 전달 툴
- 엘라스틱서치: 컨슈머 랙 정보 저장소
- 그라파나: 엘라스틱서치 정보를 시각화 & 특정 조건에 슬랙 알람을 보내는 웹 대시보드 툴

<br>

### 컨슈머 배포 프로세스

> 카프카 컨슈머 애플리케이션 운영 시 로직 변경으로 인한 배포 방법
1. 중단 배포
2. 무중단 배포
> 

<br>

**중단 배포**

- 한정된 서버 자원을 운영할 때 적합
- 신뢰성 있는 배포 시스템일 때 적합
- 신규 애플리케이션의 실행 전후를 특정 지점으로 나눌 수 있어 롤백할 때 유용

<br>

**무중단 배포**

- 인스턴스 발급과 반환이 유연한 가상 서버에서 유용
- 블루/그린 배포
    - 이전 버전, 신규 버전 애플리케이션을 동시에 띄우고 트래픽을 전환
    - 파티션 개수와 컨슈머 개수를 동일하게 실행하고 운영할 때 유용
    - 짧은 리밸런스 시간으로 배포 수행
- 롤링 배포
    - 리소스 낭비를 줄이면서 무중단 배포
    - 파티션 개수가 인스턴스 개수와 같거나 많아야
    - 파티션 개수와 리밸런스 시간이 비례해 파티션이 적을 때 효과적
- 카나리 배포
    - 작은 위험을 통해 큰 위험을 예방한다.
    - 데이터 일부분을 신규 버전에 먼저 배포해 이슈를 사전 탐지
    - 사전 테스트 완료 시 나머지 파티션에 할당된 컨슈머에 무중단 배포

<br>

## 스프링 카프카

카프카를 스프링 프레임워크에서 효과적으로 사용할 수 있도록 만들어진 라이브러리

<br>

### 스프링 카프카 프로듀서

카프카 템플릿은 ProducerFactory 클래스로 생성할 수 있다.

<br>

**기본 카프카 템플릿**

`application.yml` 에 프로듀서 옵션을 넣어 사용한다.

<br>

**test0 ~ test9까지 메시지 값을 클러스터로 보내기**

```java
@SpringBootApplication
public class SpringProducerApplication implements CommandLineRunner {
	
	private static String TOPIC_NAME = "test";

	@Autowired
	private KafkaTemplate<Integer, String> template;

	public static void main(String[] args) {
		SpringApplication application = new SpringApplication(SpringProducerApplication.class);
		application.run(args);
	}

	@Override
	public void run(String... args) {
		for (int i = 0; i < 10; i++) {
			template.send(TOPIC_NAME, "test" + i);
		}
		System.exit(0);
	}
}
```

<br>

**커스텀 카프카 템플릿**

한 스프링 카프카 애플리케이션 내부에 다양한 프로듀서 인스턴스를 생성하고 싶을 때 사용한다.

```java
@Configuration
public class KafkaTemplateConfiguration {

	@Bean
	public KafkaTemplate<String, String> customKafkaTemplate() {

		Map<String, Object> props = new HashMap<>();
		props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "my-kafka:9092");
		props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
		props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
		props.put(ProducerConfig.ACKS_CONFIG, "all");

		ProducerFactory<String, String> pf = new DefaultKafkaProducerFactory<>(props);

		return new KafkaTemplate<>(pf);
	}
}
```

```java
@SpringBootApplication
public class SpringProducerApplication implements CommandLineRunner {
	
	private static String TOPIC_NAME = "test";

	@Autowired
	private KafkaTemplate<String, String> customKafkaTemplate;

	public static void main(String[] args) {
		...
	}

	@Override
	public void run(String... args) {
		ListenableFuture<SendResult<String, String>> future = customKafkaTemplate.send(TOPIC_NAME, "test");
		future.addCallback(new KafkaSendCallback<String, String>() {
			@Override
			public void onSuccess(SendResult<String, String> result) {}

			@Override
			public void onFailure(KafkaProducerException ex) {}
		});
		System.exit(0);
	}
}
```

<br>

### 스프링 카프카 컨슈머

**컨슈머 타입**

- 레코드 리스너(Default) : 단 1개의 레코드 처리
    - MessageListener
    - AcknowledgingMessageListener
    - ConsumerAwareMessageListener
    - AcknowledgingConsumerAwareMessageListener
- 배치 리스너 : 한번에 여러 개 레코드 처리
    - BatchMessageListener
    - BatchAcknowledgingMessageListener
    - BatchConsumerAwareMessageListener
    - BatchAcknowledgingConsumerAwareMessageListener


<br>

**커밋 타입**

- RECORD : 레코드 단위 커밋
- BATCH : 레코드 모두 처리 후 커밋
- TIME : 특정 시간 이후 커밋
- COUNT : 특정 개수만큼 처리 후 커밋
- COUNT_TIME
- MANUAL
- MANUAL_IMMEDIATE


<br>

사용방식 1. 기본 리스너 컨테이너 사용

`application.yaml`에 컨슈머와 리스너 옵션을 넣어 사용한다.

```java
@SpringBootApplication
public class SpringConsumerAPplication {
	...

	@KafkaListener(topics = "test", groupId = "test-group-00")
	public void recordListener(ConsumerRecord<String, String> record) {
		logger.info(record.toString());
	}

	// 메시지 값을 파라미터로 받는 리스너
	@KafkaListener(topics = "test", groupId = "test-group-01")
	public void singleTopicListener(String messageValue) {
		logger.info(messageValue);
	}

	// 카프카 컨슈머 옵션값 부여
	@KafkaListener(topics = "test", groupId = "test-group-02",
									properties = {
																	"max.poll.interval.ms:60000",
																	"auto.offset.reset:earliest"
																})
	public void singleTopicWithPropertiesListener(String messageValue) {
		logger.info(messageValue);
	}

	// 3개의 카프카 컨슈머 스레드를 병렬처리
	@KafkaListener(topics = "test", groupId = "test-group-03", concurrency = "3")
	public void concurrentTopicListener(String messageValue) {
		logger.info(messageValue);
	}

	// 특정 토픽의 특정 파티션만 구독
	@KafkaListener(topicPartitions = {
									@TopicPartition(topic = "test01", partitions = {"0", "1"}},
									@TopicPartition(topic = "test02", partitionOffsets = 
									@PartitionOffset(partition = "0", initialOffset = "3"))
								},
								groupId = "test-group-04")
	public void listenSpecificPartition(ConsumerRecord<String, String> record) {
		logger.info(record.toString());
	}
}
```

<br>

사용방식 2. **커스텀 리스너 컨테이너**

서로 다른 설정을 가진 여러 리스너들이나 리밸런스 리스너를 구현하기 위해 사용한다.

<br>

```java
@Configuration
public class ListenerContainerConfiguration {
		
	@Bean
	public KafkaListenerContainerFactory<ConcurrentMessageListenerContainer<String, String>> customContainerFactory() {
		// 카프카 컨슈머 옵션값 설정
		Map<String, Object> props = new HashMap();
		...

		DefaultKafkaConsumerFactory cf = new DefaultKafkaConsumerFactory<>(props);
		ConcurrentKafkaListenerContainerFactory<String, String> factory = new ConcurrentKafkaListenerContainerFactory();
		factory.getContainerProperties().setConsumerRebalanceListener(new ConsumerAwareRebalanceListener() {
			@Override
			public void onPartitionsRevokedBeforeCommit(Consumer<?, ?> consumer, Collection<TopicPartition> partitions) {}

			@Override
			public void onPartitionsRevokedAfterCommit(Consumer<?, ?> consumer, Collection<TopicPartition> partitions) {}

			@Override
			public void onPartitionsAssigned(Collection<TopicPartition> partitions) {}

			@Override
			public void onPartitionsLost(Collection<TopicPartition> partitions) {}
		});

		factory.setBatchListener(false);
		factory.getContainerProperties().steAckMode(ContainerProperties.AckMode.RECORD);
		factory.setConsumerFactory(cf);

		return factory;
	}
}
```

<br>

**커스텀 리스터 컨테이너 선언 코드**

```java
@SpringBootApplication
public class SpringConsumerApplication {
	public static void main(String[] args) {
		...
	}

	@KafkaListener(topics = "test", groupId = "test-group", containerFactory = "customContainerFactory")
	public void customListener(String data) {
		logger.info(data);
	}
}
```
