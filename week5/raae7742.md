# CHAPTER 4. 카프카 상세 개념
# 토픽과 파티션

토픽을 사용함에 있어 발생하는 여러 가지 고려사항을 짚어보자.

<br>

## 적정 파티션 개수

> 토픽 생성 시 파티션 개수 고려사항
- 데이터 처리량
- 메시지 키 사용 여부
- 브로커, 컨슈머 영향도

<br>

> 데이터 처리 속도를 올리는 방법
1. 컨슈머의 처리량을 늘린다.
    1. 컨슈머 서버의 사양을 올린다.(스케일 업)
    2. GC 튜닝
    3. 파티션 개수를 늘리고 그만큼 컨슈머를 추가한다.
2. 컨슈머를 추가해 병렬처리량을 늘린다.


<br>


📝 프로듀서 전송 데이터량 < (컨슈머 데이터 처리량 * 파티션 개수)

<br>
  
1. 컨슈머 데이터 처리량은 꼭 상용 환경에서 테스트해 측정한다.
2. 프로듀서가 보내는 데이터양을 하루, 시간, 분 단위로 쪼개 예측한다.
3. 데이터 처리 순서를 지켜야 하는지 고려해 메시지 키 사용여부를 정한다.
4. 파티션 개수를 늘릴 때 브로커 당 파티션 개수를 확인하고 진행한다.

<br>
  
<br>
  
## 토픽 정리 정책(cleanup.policy)

1. delete(삭제): 데이터 완전 삭제
2. compact(압축): 동일 메시지 키의 가장 오래된 데이터 삭제

  
<br>
  
### delete policy

- 일반적인 정리 정책으로 세그먼트 단위로 삭제
- segment.bytes: 세그먼트로 저장할 용량의 단위
- retention.ms: 토픽의 데이터를 유지하는 기간(밀리초)
- retention.bytes: 토픽의 최대 데이터 크기

  
<br>
  
### compact policy

- 동일 메시지 키의 가장 오래된 데이터 삭제
- KTable과 같이 메시지 키 기반 데이터 처리 상황에서 유용
- min.cleanable.dirty.ratio : 데이터의 압축 시작 시점
- min.cleanable.dirty.ratio : 액티브 세그먼트를 제외한 남아있는 세그먼트 데이터의 tail 영역 레코드 개수와 head 영역 레코드 개수의 비율
    - tail 영역: 압축이 완료된 레코드로 중복된 메시지 키가 없다. (== clean log)
    - head 영역: 중복된 메시지 키가 있다. (== dirty log)
    
    ⇒ 옵션값이 0.5인 경우, dirty ratio가 0.5를 넘어서면 압축이 수행된다.
    
  
<br>
  
<br>

## ISR(In-Sync-Replicas)

- 리더 파티션과 팔로워 파티션이 모두 싱크가 된 상태
- replica.lag.time.max.ms: 팔로워 파티션이 데이터를 복제하는지 확인하는 주기

⇒ 데이터를 가져가지 않으면 문제가 생겼다고 판단하고 ISR 그룹에서 제외

  
<br>
  
- ISR 그룹: 팔로워 파티션은 리더로 선출될 자격을 가진다.
- 그 외: 팔로워 파티션은 리더로 선출될 자격이 없다.

⇒ unclean.leader.election.enable = true로 설정하면 그 외 팔로워 파티션도 리더로 선출할 수 있다.

  
<br>
  
> **unclean.leader.election.enable 옵션**
일부 데이터가 유실되어도 무중단 운영이 필요한 경우 → true
데이터가 유실되면 안되는 경우 → false
> 

<br>
  
<br>


# 카프카 프로듀서

프로듀서의 고급 활용법과 옵션별 동작 방식에 대해 자세히 알아보자.

<br>
  
## acks 옵션

### acks=0

- 프로듀서가 리더 파티션으로 데이터를 전송하고 데이터 저장 여부를 응답 값으로 받지 않는다.
- 데이터 전송 속도는 가장 빠르기 때문에 신뢰성보다 전송 속도가 중요할 때 사용한다.

<br>
  
### acks=1

- 프로듀서는 리더 파티션에만 정상적으로 데이터가 적재되었는지 확인한다.
- 리더 파티션에 한해서만 적재될 때까지 재시도할 수 있다.
- 팔로워 파티션이 데이터를 복제하기 직전에 장애가 발생하면 데이터가 유실될 수 있다.

<br>
  
### acks=all (or -1)

- 프로듀서가 리더와 팔로워 파티션(ISR 그룹)에 모두 정상 적재되었는지 확인한다.
- 속도가 느리지만 장애가 발생해도 안전을 보장한다.
- min.insync.replicas: 프로듀서가 데이터 적재를 확인할 최소 ISR 그룹의 파티션 개수
    - 최소 2로 설정해야 all로 설정하는 의미가 있다.
    - 브로커 개수 미만으로 꼭 설정하도록 한다.

  
<br>
  
📝 **가장 안정적인 설정 방법**
토픽 복제 개수 = 3
min.insync.replicas = 2
acks = all

  
<br>
  
  
<br>
  
## 멱등성(idempotence) 프로듀서

- 멱등성: 여러 번 연산을 수행하더라도 동일한 결과를 나타내는 것
- 멱등성 프로듀서: 동일한 데이터를 여러 번 전송해도 카프카 클러스터에 한 번만 저장됨

  
<br>
  
**enable.idempotence 옵션**

- 데이터를 브로커로 전달 시 PID와 seq #을 함께 전달해 **정확히 한번 전달을 지원**
- 동일 세션(PID 생명주기)에서만 정확히 한번 전달을 보장
- true로 설정시 retries = Integer.MAX_VALUE, acks = all로 강제 설정

  
<br>
  
<br>
  
## 트랜잭션(transaction) 프로듀서

- 다수의 파티션에 데이터 저장 시 모든 데이터에 대해 동일한 원자성을 만족시키기 위해 사용
- 원자성: 데이터들을 동일 트랜잭션으로 묶어 전체를 처리하거나 전체를 처리하지 않도록 하는 것
- `enable.idempotence = true`, `transactional.id = ${String 값}` 으로 설정
- 컨슈머에서 `isolation.level = read_committed` 로 설정
- 트랜잭션은 시작과 끝을 표현하는 레코드를 한 개 더 보내 구분한다.

  
<br>
  
<br>
  
  
# 카프카 컨슈머

컨슈머의 고급 활용법과 옵션별 동작 방식을 알아보자.

<br>
  
<br>
  
## 멀티 스레드 컨슈머

- 파티션을 여러 개로 운영한다면 파티션 개수와 컨슈머 개수를 동일하게 맞추자.
- 파티션 개수가 n개라면 컨슈머 스레드를 최대 n개 운영할 수 있다.
- 한 컨슈머 스레드에서 예외가 발생 시, 프로세스 자체가 종료될 수 있다.
- 각 스레드 간에 영향이 없도록 스레드 세이프 로직, 변수를 적용해야 한다.

> **컨슈머를 멀티 스레드로 활용하는 방식**
1. 멀티 워커 스레드 전략
2. 컨슈머 멀티 스레드 전략
> 

<br>
  
<br>
  
  
### 카프카 컨슈머 멀티 워커 스레드 전략

컨슈머 스레드는 1개만 실행하고 데이터 처리 담당인 워커 스레드를 여러 개 실행한다.

- 데이터를 워커 스레드에서 병렬 처리해 속도가 빨라진다.
- 자바의 ExecutorService 라이브러리를 사용한다.
    - Executors: 스레드 개수를 제어하는 스레드 풀 생성
    - CachedThreadPool: 스레드 실행

<br>
  
<br>
  
**레코드들을 처리하는 워커 스레드를 실행하는 코드**

```java
public class ConsumerWorker implements Runnable {
	private String recordValue;

	ConsumerWorker(String recordValue) {
		this.recordValue = recordValue;
	}

	@Override
	public void run() {
		logger.info("thread:{}\trecord:{}", Thread.currentThread().getName(), recordValue);
	}
}
```
